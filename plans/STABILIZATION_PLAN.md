# Avatar Engine â€” Stabilization Plan

> Created: 2026-02-05
> Updated: 2026-02-11
> Phase 1â€“6 (Testing): âœ… COMPLETED â€” **290** testÅ¯
> Phase 7 (Bridge Observability): ğŸŸ¡ IN PROGRESS â€” kroky 1â€“3 DONE, kroky 4â€“6 OPEN

---

## Executive Summary

AnalÃ½za odhalila **kritickÃ© mezery v testovÃ¡nÃ­**:

| Kategorie | AktuÃ¡lnÃ­ | CÃ­l |
|-----------|----------|-----|
| **Async execution** | 0 testÅ¯ | 25+ |
| **CLI commands** | 0 testÅ¯ | 20+ |
| **Error recovery** | ~3 testy | 15+ |
| **Edge cases** | ~5 testÅ¯ | 25+ |
| **Race conditions** | 0 testÅ¯ | 5+ |

**HlavnÃ­ problÃ©m:** Testy testujÃ­ kÃ³d, ne use-casy. UÅ¾ivatel mÅ¯Å¾e mÃ­t faleÅ¡nÃ½ pocit bezpeÄÃ­.

---

## KritickÃ© Use-Case Testy (ChybÃ­!)

### UC-1: ZÃ¡kladnÃ­ chat flow
```
User wants to: Send a message and get a response

EXPECTED:
1. engine.start() â†’ bridge warm up
2. engine.chat("Hello") â†’ response with content
3. response.success == True
4. response.content is not empty
5. engine.session_id is set
6. engine.history has 2 messages (user + assistant)

NOT TESTED:
- Actual subprocess communication
- JSONL message format
- Response parsing
- Session ID extraction
```

### UC-2: Streaming response
```
User wants to: Stream response chunks in real-time

EXPECTED:
1. async for chunk in engine.chat_stream("Tell me a story"):
2. Each chunk is a non-empty string
3. Chunks accumulate to full response
4. TextEvent emitted for each chunk
5. Final response in history

NOT TESTED:
- Actual streaming from subprocess
- Partial message handling
- Event emission timing
```

### UC-3: Provider switching
```
User wants to: Switch from Gemini to Claude mid-session

EXPECTED:
1. engine = AvatarEngine(provider="gemini")
2. await engine.start()
3. await engine.chat("Hello") â†’ works
4. await engine.switch_provider("claude")
5. await engine.chat("Hello again") â†’ works with Claude
6. History cleared or preserved (configurable?)

NOT TESTED:
- Cleanup of old bridge
- State consistency
- Error during switch
```

### UC-4: Auto-restart on failure
```
User wants to: Engine recovers from bridge crash

EXPECTED:
1. engine.chat("Hello") â†’ success
2. Bridge process crashes (externally killed)
3. engine.chat("Hello again") â†’ auto-restarts
4. Response success after restart
5. restart_count incremented

NOT TESTED:
- Crash detection
- Restart logic
- State recovery
- Max restarts limit
```

### UC-5: GUI event integration
```
User wants to: Update GUI in real-time during AI response

EXPECTED:
1. @engine.on(TextEvent) â†’ updates speech bubble
2. @engine.on(ToolEvent) â†’ shows tool usage
3. Events fire during chat_stream()
4. Events contain correct data

NOT TESTED:
- Event emission from real responses
- Handler error handling
- Event ordering
```

### UC-6: CLI single message
```
User wants to: avatar chat "What is 2+2?"

EXPECTED:
1. Output: "4" (or similar)
2. Exit code: 0
3. --json output is valid JSON
4. --stream shows chunks
5. Error message on failure

NOT TESTED:
- CLI command execution
- Output format
- Error handling
```

### UC-7: MCP tool usage
```
User wants to: AI uses custom tools via MCP

EXPECTED:
1. Configure MCP server
2. engine.chat("Use the calculator tool")
3. ToolEvent with status="started"
4. ToolEvent with status="completed"
5. Response includes tool result

NOT TESTED:
- MCP server integration
- Tool event emission
- Tool call parsing
```

### UC-8: Graceful shutdown
```
User wants to: Clean shutdown on SIGTERM

EXPECTED:
1. engine.install_signal_handlers()
2. Send SIGTERM to process
3. engine stops cleanly
4. Bridge process terminated
5. No zombie processes

NOT TESTED:
- Signal handling during chat
- Pending request handling
- Process cleanup
```

### UC-9: Rate limiting
```
User wants to: Prevent API rate limit errors

EXPECTED:
1. Configure rate_limit_rpm=2
2. Send 5 rapid chat() calls
3. First 2 succeed immediately
4. Next 3 wait for rate limit
5. All eventually succeed

NOT TESTED:
- Actual waiting behavior
- Time-based verification
- Stats accuracy
```

### UC-10: Cost tracking (Claude)
```
User wants to: Monitor and limit costs

EXPECTED:
1. Configure max_budget_usd=0.10
2. engine.chat() accumulates cost
3. CostEvent emitted with cost
4. is_over_budget() returns True when exceeded
5. Subsequent chats rejected

NOT TESTED:
- Cost accumulation
- Budget enforcement
- CostEvent emission
```

---

## ImplementaÄnÃ­ PlÃ¡n

### Phase 1: Async Subprocess Mocking (Priority: CRITICAL)
```
Soubor: tests/test_async_flow.py

Testy:
1. test_chat_full_flow - subprocess mock, JSONL exchange
2. test_chat_stream_full_flow - streaming mock
3. test_chat_timeout_handling - timeout scenarios
4. test_chat_process_crash - unexpected exit
5. test_chat_partial_json - incomplete response
```

### Phase 2: CLI Integration Tests (Priority: HIGH)
```
Soubor: tests/test_cli.py

Testy:
1. test_chat_command_basic - "avatar chat 'hello'"
2. test_chat_command_json - "--json output"
3. test_chat_command_provider - "-p claude"
4. test_repl_command_exit - "/exit"
5. test_health_command - "avatar health --check-cli"
6. test_mcp_list - "avatar mcp list"
7. test_mcp_add_remove - add/remove MCP server
```

### Phase 3: Error Recovery Tests (Priority: HIGH)
```
Soubor: tests/test_error_recovery.py

Testy:
1. test_auto_restart_on_crash - bridge crash â†’ restart
2. test_max_restarts_limit - doesn't restart forever
3. test_fallback_persistent_to_oneshot - persistent fails â†’ oneshot
4. test_gemini_acp_fallback - ACP fails â†’ oneshot
5. test_error_event_emission - ErrorEvent fired on failure
```

### Phase 4: Event System Tests (Priority: MEDIUM)
```
Soubor: tests/test_event_integration.py

Testy:
1. test_text_event_during_stream - chunks â†’ events
2. test_tool_event_lifecycle - started â†’ completed
3. test_state_event_transitions - all state changes
4. test_cost_event_emission - cost tracking
5. test_handler_exception_handling - handler throws
```

### Phase 5: Edge Cases (Priority: MEDIUM)
```
Soubor: tests/test_edge_cases.py

Testy:
1. test_concurrent_chat_calls - race conditions
2. test_switch_provider_during_chat - state corruption
3. test_very_long_response - memory handling
4. test_empty_response - edge case
5. test_unicode_content - encoding
6. test_history_limit - max_history enforcement
```

### Phase 6: Gemini ACP Tests (Priority: MEDIUM)
```
Soubor: tests/test_gemini_acp.py

Testy:
1. test_acp_initialization_flow - full startup
2. test_acp_authentication_failure - auth error
3. test_acp_session_creation - new_session
4. test_acp_prompt_streaming - session updates
5. test_acp_thinking_extraction - thinking content
```

---

## Metriky ÃšspÄ›chu

| Metrika | AktuÃ¡lnÃ­ | CÃ­l | Status |
|---------|----------|-----|--------|
| Celkem testÅ¯ | **290** | 280+ | âœ… |
| Async flow testy | **15** | 25 | âœ… |
| CLI testy | **23** | 20 | âœ… |
| Error recovery | **12** | 15 | âœ… |
| Edge cases | **19** | 25 | âœ… |
| Event integration | **12** | 10 | âœ… |
| Gemini ACP | **25** | 20 | âœ… |

---

## Rizika

| Riziko | PravdÄ›podobnost | Dopad | Mitigace |
|--------|-----------------|-------|----------|
| Testy zÃ¡visÃ­ na reÃ¡lnÃ½ch CLI | ~~VysokÃ¡~~ | ~~VysokÃ½~~ | âœ… Mock subprocess |
| Race conditions v async kÃ³du | ~~StÅ™ednÃ­~~ | ~~VysokÃ½~~ | âœ… IzolovanÃ© testy |
| Flaky testy (timing) | ~~StÅ™ednÃ­~~ | ~~StÅ™ednÃ­~~ | âœ… DeterministickÃ© mocky |

---

## DalÅ¡Ã­ Kroky

1. âœ… VytvoÅ™it stabilizaÄnÃ­ plÃ¡n
2. âœ… Implementovat Phase 1 (async subprocess) - 15 testÅ¯
3. âœ… Implementovat Phase 2 (CLI) - 23 testÅ¯
4. âœ… Implementovat Phase 3 (Error recovery) - 12 testÅ¯
5. âœ… Implementovat Phase 4 (Events) - 12 testÅ¯
6. âœ… Implementovat Phase 5 (Edge cases) - 19 testÅ¯
7. âœ… Implementovat Phase 6 (Gemini ACP) - 25 testÅ¯
8. âœ… DosÃ¡hnout 280+ testÅ¯ â†’ **290 testÅ¯**

---

# Phase 7: Bridge Observability â€” â€SlepÃ½ uÅ¾ivatel"

> Added: 2026-02-11
> Status: ğŸ”´ OPEN
> Priority: **CRITICAL**
> Princip: **SlepÃ½ uÅ¾ivatel je to nejhorÅ¡Ã­, co se nÃ¡m mÅ¯Å¾e stÃ¡t.**

## ProblÃ©m

UÅ¾ivatel odeslal zprÃ¡vu pÅ™es GUI, Gemini CLI zpracovÃ¡vala request 2+ minuty,
a pak vÅ¡e spadlo na server-side timeout. UÅ¾ivatel nemÄ›l **Å¾Ã¡dnou informaci**
o tom, co se dÄ›je:

- Å½Ã¡dnÃ½ progress â€” jen spinning orb
- Å½Ã¡dnÃ¡ diagnostika â€” stderr z CLI zahozeno (`stderr=None`)
- Å½Ã¡dnÃ½ kontext v timeout chybÄ› â€” jen "request timed out"
- Po timeoutu ghost events â€” bust mluvila a neÅ¡la zastavit

ÄŒÃ¡st problÃ©mÅ¯ (ghost events, timeout hodnota, connection overlay) jsme vyÅ™eÅ¡ili
v commitech `dde24b9` a `f46efd2`. **Ale jÃ¡dro problÃ©mu zÅ¯stÃ¡vÃ¡: nevidÃ­me
dovnitÅ™ CLI subprocessÅ¯.**

---

## Audit vÅ¡ech bridge procesÅ¯

### 1. ACP stderr zahozeno (CRITICAL)

**Gemini:** `avatar_engine/bridges/gemini.py:362`
```python
stderr=None,  # â† VEÅ KERÃ diagnostickÃ½ output zahozenÃ½
```

**Codex:** `avatar_engine/bridges/codex.py:244`
```python
stderr=None,  # â† VEÅ KERÃ diagnostickÃ½ output zahozenÃ½
```

**Claude (OK):** `avatar_engine/bridges/claude.py:165`
```python
stderr=asyncio.subprocess.PIPE,  # âœ… SprÃ¡vnÄ› â€” zachytÃ¡vÃ¡no
```

**Dopad:** Gemini CLI a Codex CLI vypisujÃ­ na stderr:
- Auth chyby, token refresh problÃ©my
- Rate limit warnings
- Model availability problÃ©my
- InternÃ­ progress ("Connecting...", "Authenticating...")
- Crash stacktrace

**VÅ¡e zahozeno.** UÅ¾ivatel nevidÃ­ nic. AdministrÃ¡tor nevidÃ­ nic. Ani logy nemajÃ­ stderr.

### 2. Infrastruktura EXISTUJE, ale nenÃ­ napojena (CRITICAL)

Pipeline pro diagnostiku je **kompletnÄ› vybudovanÃ½**, jen ACP ho nepouÅ¾Ã­vÃ¡:

```
bridges/base.py:320  _monitor_stderr()     â€” Äte stderr, klasifikuje, emituje
                                              â†“
bridges/base.py:334  _on_event(diagnostic)  â€” posÃ­lÃ¡ do engine
                                              â†“
engine.py:705-712    DiagnosticEvent emit   â€” emituje event
                                              â†“
web/bridge.py:133    _on_diagnostic()       â€” broadcastuje klientÅ¯m
                                              â†“
web/protocol.py:35   "diagnostic" type      â€” WS message type
                                              â†“
Frontend                                    â€” (zatÃ­m nezpracovÃ¡vÃ¡)
```

Claude bridge tuto pipeline pouÅ¾Ã­vÃ¡ (persistent mode, `stderr=PIPE`).
Gemini a Codex ACP procesy ji **obchÃ¡zejÃ­** â€” majÃ­ vlastnÃ­ subprocess spawn
s `stderr=None`.

### 3. ACP callback exceptions spolknuty (HIGH)

**Gemini:** `avatar_engine/bridges/gemini.py:497-500`
```python
try:
    self._handle_acp_update_inner(session_id, update)
except Exception as exc:
    logger.debug(f"Error in ACP update handler: {exc}", exc_info=True)
    # â† DEBUG level! UÅ¾ivatel nikdy neuvidÃ­.
```

**Codex:** `avatar_engine/bridges/codex.py:377-380`
```python
try:
    self._handle_acp_update_inner(session_id, update)
except Exception as exc:
    logger.debug(f"Error in ACP update handler: {exc}", exc_info=True)
    # â† StejnÃ½ problÃ©m.
```

**Dopad:** Pokud dojde k chybÄ› pÅ™i zpracovÃ¡nÃ­ ACP update (parsovÃ¡nÃ­,
neoÄekÃ¡vanÃ½ formÃ¡t, missing field), exception se zaloguje na DEBUG
a request pokraÄuje bez odpovÄ›di â€” nakonec spadne na timeout.

### 4. Timeout bez kontextu (HIGH)

**Server:** `avatar_engine/web/server.py:554-559`
```python
except asyncio.TimeoutError:
    error_text = f"No response from engine â€” request timed out{size_hint}"
```

ChybÃ­:
- JakÃ½ byl engine state pÅ™i timeoutu (thinking? tool_executing? idle?)
- Kolik eventÅ¯ pÅ™iÅ¡lo pÅ™ed timeoutem
- PoslednÃ­ diagnostickÃ¡ zprÃ¡va z CLI
- Jak dlouho trvaly jednotlivÃ© fÃ¡ze (thinking vs tool execution)

### 5. Å½Ã¡dnÃ½ heartbeat bÄ›hem dlouhÃ½ch operacÃ­ (MEDIUM)

PÅ™i 10-minutovÃ©m ACP requestu:
- Server neposÃ­lÃ¡ Å¾Ã¡dnÃ½ keepalive
- Frontend nevÃ­, jestli je engine mrtvÃ½ nebo pracuje
- WebSocket timeout v browseru mÅ¯Å¾e spojenÃ­ zavÅ™Ã­t
- UÅ¾ivatel nemÃ¡ dÅ¯vod Äekat â€” vypadÃ¡ to jako zamrzlÃ©

### 6. Auth/rate-limit chyby neviditelnÃ© (MEDIUM)

Gemini CLI mÅ¯Å¾e internÄ›:
- ÄŒekat na OAuth token refresh (uvÃ­znutÃ© na auth prompt?)
- Dostat 429 rate limit a Äekat na retry
- Dostat 403 na model, co nenÃ­ dostupnÃ½

**Nic z toho nevidÃ­me.** Viz problÃ©m #1 (stderr zahozeno).

### 7. Claude --debug flag (LOW â€” jen Claude)

Claude bridge podporuje `--debug` flag pro extra vÃ½pis. Gemini a Codex
nemajÃ­ ekvivalent. ZvÃ¡Å¾it verbose/debug mode pro vÅ¡echny bridges.

---

## ImplementaÄnÃ­ plÃ¡n

### Krok 1: stderr=PIPE pro ACP procesy (CRITICAL, ~30 min)

**Soubory:**
- `avatar_engine/bridges/gemini.py:362` â€” `stderr=None` â†’ `stderr=asyncio.subprocess.PIPE`
- `avatar_engine/bridges/codex.py:244` â€” `stderr=None` â†’ `stderr=asyncio.subprocess.PIPE`

**Co udÄ›lat:**
1. ZmÄ›nit `stderr=None` na `stderr=asyncio.subprocess.PIPE`
2. Spustit `_monitor_stderr_acp()` background task (analogicky k base.py:304)
3. V ACP mode nelze pouÅ¾Ã­t base._monitor_stderr() pÅ™Ã­mo (jinÃ½ self._proc),
   takÅ¾e: pÅ™idat metodu `_start_stderr_monitor()` do ACP setup
4. Stderr output â†’ `self._on_event({"type": "diagnostic", ...})`

**Riziko:** stderr buffer se mÅ¯Å¾e zaplnit pokud neÄteme â†’ process freezne.
Proto MUSÃ bÃ½t background task, ne jednorÃ¡zovÃ© ÄtenÃ­.

### Krok 2: Callback exceptions â†’ ErrorEvent (HIGH, ~20 min)

**Soubory:**
- `avatar_engine/bridges/gemini.py:499` â€” `logger.debug` â†’ `logger.warning` + emit ErrorEvent
- `avatar_engine/bridges/codex.py:379` â€” stejnÄ›

**Co udÄ›lat:**
1. ZvÃ½Å¡it log level z DEBUG na WARNING
2. Emitovat pÅ™es `self._on_event({"type": "error", "error": str(exc)})`
3. Frontend pak zobrazÃ­ chybu (infrastructure uÅ¾ funguje)

### Krok 3: Timeout s kontextem (HIGH, ~30 min)

**Soubor:** `avatar_engine/web/server.py:554-567`

**Co udÄ›lat:**
1. PÅ™ed `asyncio.wait_for()` uloÅ¾it start time + engine state
2. V timeout handleru:
   - AktuÃ¡lnÃ­ engine state
   - Elapsed time per phase (pokud sledujeme)
   - PoÄet pÅ™ijatÃ½ch eventÅ¯
   - PoslednÃ­ diagnostickÃ¡ zprÃ¡va
3. FormÃ¡tovat do error message:
   ```
   Request timed out after 600s.
   Last state: tool_executing (gemini-3-pro-preview)
   Events received: 47 (last: thinking at +45s)
   Last diagnostic: "Executing tool: list_directory"
   ```

### Krok 4: Heartbeat / progress ping (MEDIUM, ~45 min)

**Soubory:**
- `avatar_engine/web/server.py` â€” heartbeat task
- `avatar_engine/web/bridge.py` â€” forward heartbeat
- Frontend: `useAvatarWebSocket.ts` â€” handle heartbeat type

**Co udÄ›lat:**
1. BÄ›hem `asyncio.wait_for()` spustit background task:
   ```python
   async def heartbeat():
       elapsed = 0
       while True:
           await asyncio.sleep(15)
           elapsed += 15
           brg.broadcast_message({
               "type": "heartbeat",
               "data": {
                   "elapsed": elapsed,
                   "engine_state": eng.state.value,
                   "events_received": event_count,
               }
           })
   ```
2. Frontend: zobrazit elapsed time + stav v compact mode
3. ZruÅ¡it heartbeat task po dokonÄenÃ­/timeoutu

### Krok 5: Frontend diagnostic panel (MEDIUM, ~1h)

**Soubory:**
- `examples/web-demo/src/hooks/useAvatarWebSocket.ts` â€” handle `diagnostic` type
- `examples/web-demo/src/components/CompactMessages.tsx` â€” diagnostic overlay
- `examples/web-demo/src/components/StatusBar.tsx` â€” diagnostic indicator

**Co udÄ›lat:**
1. WebSocket handler pro `diagnostic` type â†’ uklÃ¡dat do state
2. Compact mode: pod thinking/tool info zobrazit diagnostiku
3. Fullscreen: diagnostika v status baru
4. Fade-out po 5s, max 3 Å™Ã¡dky viditelnÃ©

### Krok 6: Verbose/debug mode pro vÅ¡echny bridges (LOW, ~30 min)

**Soubory:**
- `avatar_engine/bridges/gemini.py` â€” `--log_level=debug` pro gemini-cli
- `avatar_engine/bridges/codex.py` â€” verbose flag pro codex
- `avatar_engine/config.py` â€” `debug_bridges: bool` config option

---

## Stav po pÅ™edchozÃ­ch fixech (commity dde24b9, f46efd2)

| Fix | Soubor | Stav |
|-----|--------|------|
| Client-side timeout odstranÄ›n | useAvatarChat.ts | âœ… DONE |
| Server timeout 120â†’600s | server.py:545 | âœ… DONE |
| Error fence (ghost events) | useAvatarWebSocket.ts | âœ… DONE |
| stopResponse â†’ idle+thinking_end | useAvatarWebSocket.ts | âœ… DONE |
| Connection status overlay | CompactChat.tsx | âœ… DONE |
| Error banner v compact mode | CompactChat.tsx | âœ… DONE |
| Tool/thinking visibility | CompactMessages.tsx | âœ… DONE |
| 25 error-handling testÅ¯ | error-handling.test.ts | âœ… DONE |

---

## Priority Matrix

| # | Krok | Priorita | Effort | Dopad | Stav |
|---|------|----------|--------|-------|------|
| 1 | stderr=PIPE pro ACP | ğŸ”´ CRITICAL | 30 min | NejvÄ›tÅ¡Ã­ â€” odemkne VEÅ KEROU diagnostiku | âœ… DONE |
| 2 | Callback exceptions â†’ ErrorEvent | ğŸŸ  HIGH | 20 min | OdhalÃ­ tichÃ© chyby v ACP update handleru | âœ… DONE |
| 3 | Timeout s kontextem | ğŸŸ  HIGH | 30 min | UÅ¾ivatel vÃ­ PROÄŒ to trvalo / spadlo | âœ… DONE |
| 4 | Heartbeat / progress | ğŸŸ¡ MEDIUM | 45 min | UÅ¾ivatel vÃ­ Å½E engine pracuje | OPEN |
| 5 | Frontend diagnostic panel | ğŸŸ¡ MEDIUM | 1h | Zobrazit diagnostiku v GUI | OPEN |
| 6 | Debug mode pro bridges | ğŸŸ¢ LOW | 30 min | Extra vÃ½pis pro vÃ½voj/debugging | OPEN |

**CelkovÃ½ effort:** ~4h
**ROI:** ExtrÃ©mnÄ› vysokÃ½ â€” transformuje "slepÃ©ho uÅ¾ivatele" na informovanÃ©ho.

---

## Test Plan pro Phase 7

### NovÃ© testy:

```
tests/test_bridge_observability.py:
1. test_gemini_acp_stderr_captured - stderr=PIPE, monitor task running
2. test_codex_acp_stderr_captured - stejnÄ› pro Codex
3. test_stderr_diagnostic_event_emitted - stderr line â†’ DiagnosticEvent
4. test_acp_callback_error_surfaced - exception â†’ ErrorEvent (ne jen debug log)
5. test_timeout_includes_context - timeout error mÃ¡ engine state + event count
6. test_heartbeat_during_long_request - heartbeat messages posÃ­lÃ¡ny
7. test_heartbeat_stops_after_response - heartbeat zruÅ¡en po odpovÄ›di

examples/web-demo/src/__tests__/diagnostic-display.test.ts:
8. test_diagnostic_message_rendered - diagnostic type â†’ zobrazenÃ­ v UI
9. test_heartbeat_updates_elapsed - heartbeat â†’ elapsed time v compact mode
10. test_diagnostic_fadeout - diagnostika zmizÃ­ po 5s
```

---

## Architektura diagnostickÃ©ho pipeline (reference)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     stderr      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     _on_event     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  gemini-cli  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ GeminiBridge â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ AvatarEngine â”‚
â”‚  (subprocess)â”‚  asyncio.PIPE   â”‚ _monitor_acp â”‚  {"type":"diag"}  â”‚  _on_bridge  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚    _stderr()  â”‚                   â”‚    _event()  â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                          â”‚
                                                                   emit(DiagnosticEvent)
                                                                          â”‚
                                                                          â–¼
                                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                   â”‚ WebBridge    â”‚
                                                                   â”‚ _on_diag()   â”‚
                                                                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                          â”‚
                                                                   broadcast_message
                                                                   {"type":"diagnostic"}
                                                                          â”‚
                                                                          â–¼
                                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                   â”‚  Frontend WS â”‚
                                                                   â”‚  diagnostic  â”‚
                                                                   â”‚  handler     â”‚
                                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Klasifikace stderr (existujÃ­cÃ­ â€” base.py:_classify_stderr_level)

```
"error", "fatal", "critical"  â†’  level: "error"
"warn"                        â†’  level: "warning"
"debug", "trace"              â†’  level: "debug"
default                       â†’  level: "info"
```
